# <p style="padding:10px;background-color:orange;margin:0;color:black;font-family:newtimeroman;font-size:150%;text-align:center;border: 15px 50px;overflow:hidden;font-weight:500">Housing price prediction</p>

<p style="text-align:center; ">
<img src="https://images.all-free-download.com/images/graphiclarge/real_estate_broker_job_design_element_businessman_house_sketch_cartoon_design_6921617.jpg" style='width: 500px; height: 300px;'>
</p>


<p style="text-align:justify; ">
    
In this project, I utilize several machine learning approaches to predict the sale prices of homes in Iowa.This project was part of a [Kaggle competition](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview) that I participated in. My goal with this project was to help me practice different types of regression modeling while also exploring new approaches for optimizing my models. 
</p> 


# <p style="padding:10px;background-color:orange;margin:0;color:black;font-family:newtimeroman;font-size:100%;text-align:center;border: 15px 50px;overflow:hidden;font-weight:500">Data</p>

This dataset was compiled by Dean De Cock for use in data science education. It's an incredible alternative for data scientists looking for a modernized and expanded version of the often cited Boston Housing dataset. 

There are 79 explanatory variables each represented by a column in the dataset. The dependent varaible here is the home sale price. 


# <p style="padding:10px;background-color:orange;margin:0;color:black;font-family:newtimeroman;font-size:100%;text-align:center;border: 15px 50px;overflow:hidden;font-weight:500">Approach</p>

### Here is a breakdown of my approach to the project:

1. Dataset exploratation and basic cleaning
2. Exploratory data analysis (EDA)
3. Data Transformation & pipeline construction
4. Data Modeling and parameter tuning (Linear Regression, Random Forest, XGBoost)
5. Neural Network Modeling (MLP)
6. Feature engineering
7. Remodeling (both supervised and unsupervised approaches) 
8. Evaluation and submission

### I utilized 4 different models in this project:
1. simple linear regression
2. Random Forest
3. Extream Gradient Boosting (XGBoost)
4. Neural Networks (MLP)

### Other considerations 

For some parts of this project, I used ChatGPT to help me figure out how to optimize my modeling, I also looked at variety of approaches from other contestants which helped guide my own approach. In the future, I'd like to use the TF-TN (tensorflow) to attempt the project since I was unable to get the package to work due to lack of Windows support and an error with my WSL
